from transformers import pipeline
import torch
import gym
from lamorel import Caller, lamorel_init
from lamorel import BaseUpdater, BaseModuleFunction
import subprocess
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, AutoModel

# Wrapper für die Interaktion mit den LLM-Modellen
class LLMClient:
    def __init__(self, command_model_name):
        tokenizer_command = AutoTokenizer.from_pretrained(command_model_name, torch_dtype=torch.float16)
        model_command = AutoModelForCausalLM.from_pretrained(command_model_name, torch_dtype=torch.float16, trust_remote_code=True, load_in_8bit=True)
        self.command_model = pipeline("text-generation", model=model_command, tokenizer=tokenizer_command)


    def action_to_command(self, action):
        command_prompt = f"Extract a single concise terminal command from the following input {action}. Provide only the command itself to execute it in a Terminal, without any additional characters, explanation."
        command = self.command_model(command_prompt, max_new_tokens=1024, do_sample=True, temperature=0.5, top_k=40,
                                     top_p=0.85)
        #print(command)
        command = command[0]['generated_text']
        command = self.remove_input_text(command, command_prompt)
        lines = command.split('\n')
        non_empty_lines = [line for line in lines if line.strip() != '']
        lines = '\n'.join(non_empty_lines)
        lines = self.remove_input_text(lines, "Command: ")
        lines = self.remove_input_text(lines, "Final answer: ")
        lines = self.remove_input_text(lines, "Answer: ")
        lines = self.remove_input_text(lines, "```")
        return lines

    def remove_input_text(self, text, text_to_remove):
        return text.replace(text_to_remove, '')


# Erweiterung der PentestEnv um die Interaktion mit den LLMs
class PentestEnvLLM(gym.Env):
    def __init__(self):
        super().__init__()
        self.observation_space = gym.spaces.Text(max_length=1000)  # Definiert den Beobachtungsraum als Text
        #self.action_space = gym.spaces.Text()  # Der Aktionsraum bleibt undefiniert
        self.llm_client = LLMClient("uukuguy/speechless-code-mistral-7b-v1.0")
        self.current_observation = ""
        self.target_flag = "flag{access_the_machine}"
        self.commands = []

    def step(self, action):
        rwards = []
        # Wandelt die Aktion in einen Terminalbefehl um
        command = self.llm_client.action_to_command(action)
        output = self.execute_command(command)
        reward = self.evaluate_output(output, command)
        rwards.append(reward)
        done = self.check_if_done(output)
        return output, reward, done, {}

    def execute_command(self, command):
        print("Konsoleneingabe:" + str(command))
        try:
            timeout_duration = 120
            completed_process = subprocess.run(command, shell=True, capture_output=True, text=True,
                                               timeout=timeout_duration)
            #print("completed_process:")
            #print(completed_process.stdout.strip())
            return completed_process.stdout.strip()
        except subprocess.TimeoutExpired:
            print("Timeout")
            return "Timeout: Der Befehl hat zu lange gedauert und wurde abgebrochen."
        except subprocess.CalledProcessError as e:
            return f"Fehlercode: {e.returncode}, Fehlermeldung: {e.output}"

    def evaluate_output(self, output, command):
        # Bewertet die Terminalausgabe, um die Belohnung zu bestimmen
        done = False
        first_word = command.split()
        if len(first_word) == 0:
            return -10
        else:
            self.commands.append(first_word[0])

        if "help" in output or "command not found" in output or "Fehlercode" in output:  # Bestrafung für falsche Befehle
            print("Fehler gefunden")
            return -50
        elif "flag{access_the_machine}" in output:  # Belohnung für das Finden der Flagge
            return 100
        elif "success" in output or "completed" in output:
            return 10
        elif output == "" or command == "":
            return -10
        elif self.check_occurrences_in_list(self.commands, first_word[0]) and "Timeout" in output:
            return -15
        elif "Timeout" in output:
            return -2
        elif self.check_occurrences_in_list(self.commands, first_word[0]):  # Befehl zählen und bei 3x Bestrafen
            return -5
        else:
            return -1

    def check_occurrences_in_list(self, word_list, target):
        threshold = 3
        count = word_list.count(target)
        return count >= threshold
    def check_if_done(self, output):
        # Prüft, ob das Ziel erreicht wurde
        return "flag.txt" in output

    def reset(self):
        # Setzt die Umgebung zurück
        self.current_observation = ""
        return self.current_observation


if __name__ == "__main__":
    TARGET_IP = input("IP der Pentest-Umgebung: ")
    env = PentestEnvLLM(TARGET_IP)